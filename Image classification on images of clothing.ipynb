{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying Fashion-MNIST\n",
    "\n",
    "Lets build and train a neural network. we'll be using the [Fashion-MNIST dataset](https://github.com/zalandoresearch/fashion-mnist), a drop-in replacement for the MNIST dataset. MNIST is actually quite trivial with neural networks where you can easily achieve better than 97% accuracy. Fashion-MNIST is a set of 28x28 greyscale images of clothes. It's more complex than MNIST, so it's a better representation of the actual performance of your network, and a better representation of datasets you'll use in the real world.\n",
    "\n",
    "<img src='assets/fashion-mnist-sprite.png' width=500px>\n",
    "\n",
    "In this notebook, we'll build your own neural network. \n",
    "\n",
    "First off, let's load the dataset through torchvision.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import helper\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))])\n",
    "# Download and load the training data\n",
    "trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Download and load the test data\n",
    "testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see one of the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = next(iter(trainloader))\n",
    "helper.imshow(image[0,:]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the network\n",
    "\n",
    "Here we should define your network. As with MNIST, each image is 28x28 which is a total of 784 pixels, and there are 10 classes. You should include at least one hidden layer. We suggest you use ReLU activations for the layers and to return the logits or log-softmax from the forward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the network architecture\n",
    "\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "input_size = 784\n",
    "hidden_sizes = [256,128,64]          \n",
    "output_size = 10\n",
    "\n",
    "model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[0],hidden_sizes[1]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[1],hidden_sizes[2]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[2], output_size),\n",
    "                      nn.LogSoftmax(dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the network\n",
    "\n",
    "Now we will create your network and train it. First you'll want to define the criterion and the optmizer\n",
    "\n",
    "Then write the training code.\n",
    "\n",
    "we will later try adjusting the hyperparameters (hidden units, learning rate, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-292ce9afbd2b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcriterion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNLLLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.003\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
